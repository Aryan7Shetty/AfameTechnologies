# -*- coding: utf-8 -*-
"""Afame_P3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1olad-XRhtBtvxmg6dEOW9Wtiu005546J
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

df = pd.read_csv('Titanic-Dataset.csv')
df

# Data Exploration
print("Data Exploration:")
print(df.info())
print(df.describe())

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Handle missing values
df.dropna(subset=['Age', 'Embarked'], inplace=True)
df['Cabin'] = df['Cabin'].fillna('Unknown')

# Convert categorical variables into numerical representations
df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})
df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})

# Feature Engineering
X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]
y = df['Survived']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Selection and Training
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)
y_pred

# Model Evaluation
print("\nModel Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

import numpy as np

# Create a DataFrame for actual and predicted values
predictions_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

# Plot actual vs predicted outcomes
plt.figure(figsize=(8, 5))
plt.scatter(predictions_df.index, predictions_df['Actual'], color='blue', label='Actual', alpha=0.5)
plt.scatter(predictions_df.index, predictions_df['Predicted'], color='red', label='Predicted', alpha=0.5)
plt.xlabel('Index')
plt.ylabel('Survival')
plt.title('Actual vs Predicted Survival')
plt.legend()
plt.show()

import matplotlib.pyplot as plt

# Plot feature importances
plt.figure(figsize=(8, 5))
feature_importances = pd.Series(model.feature_importances_, index=X.columns)
feature_importances.nlargest(10).plot(kind='barh', color='skyblue')
plt.title('Top 10 Feature Importances')
plt.xlabel('Relative Importance')
plt.ylabel('Feature')
plt.show()